name: Train model
description: Train a RandomForestRegressor model and save it.
inputs:
- {name: processed_path, type: String, description: Path to the processed.pkl file}
- {name: model_path, type: String, description: Path where the model.pkl file will
    be saved}
- {name: n_estimators, type: Integer, description: 'Number of trees in the random
    forest (default: 100)', default: '100', optional: true}
outputs:
- {name: Output, type: String}
implementation:
  container:
    image: python:3.10
    command:
    - sh
    - -c
    - (PIP_DISABLE_PIP_VERSION_CHECK=1 python3 -m pip install --quiet --no-warn-script-location
      'mlflow' 'pandas' 'numpy' 'scikit-learn' 'joblib' || PIP_DISABLE_PIP_VERSION_CHECK=1
      python3 -m pip install --quiet --no-warn-script-location 'mlflow' 'pandas' 'numpy'
      'scikit-learn' 'joblib' --user) && "$0" "$@"
    - sh
    - -ec
    - |
      program_path=$(mktemp)
      printf "%s" "$0" > "$program_path"
      python3 -u "$program_path" "$@"
    - |
      def train_model(processed_path , model_path , n_estimators  = 100)  :
          """
          Train a RandomForestRegressor model and save it.

          Args:
              processed_path: Path to the processed.pkl file
              model_path: Path where the model.pkl file will be saved
              n_estimators: Number of trees in the random forest (default: 100)

          Returns:
              String path of the saved model file
          """
          # Convert to Path objects
          processed_path = Path(processed_path)
          model_path = Path(model_path)

          # Ensure destination directory exists
          model_path.parent.mkdir(parents=True, exist_ok=True)

          # Start MLflow run
          with mlflow.start_run(run_name="training"):
              # Load processed.pkl
              processed_data = joblib.load(processed_path)

              X_train = processed_data['X_train']
              y_train = processed_data['y_train']
              X_test = processed_data['X_test']
              y_test = processed_data['y_test']

              # Train RandomForestRegressor
              model = RandomForestRegressor(n_estimators=n_estimators, random_state=42)
              model.fit(X_train, y_train)

              # Evaluate model
              train_score = model.score(X_train, y_train)
              test_score = model.score(X_test, y_test)

              # Save model.pkl using joblib
              joblib.dump(model, model_path)

              # Log parameters
              mlflow.log_param("n_estimators", n_estimators)
              mlflow.log_param("random_state", 42)
              mlflow.log_param("processed_file", str(processed_path))

              # Log metrics
              mlflow.log_metric("train_score", train_score)
              mlflow.log_metric("test_score", test_score)

              # Log model artifact
              mlflow.log_artifact(str(model_path))

          return str(model_path)

      def _serialize_str(str_value: str) -> str:
          if not isinstance(str_value, str):
              raise TypeError('Value "{}" has type "{}" instead of str.'.format(
                  str(str_value), str(type(str_value))))
          return str_value

      import argparse
      _parser = argparse.ArgumentParser(prog='Train model', description='Train a RandomForestRegressor model and save it.')
      _parser.add_argument("--processed-path", dest="processed_path", type=str, required=True, default=argparse.SUPPRESS)
      _parser.add_argument("--model-path", dest="model_path", type=str, required=True, default=argparse.SUPPRESS)
      _parser.add_argument("--n-estimators", dest="n_estimators", type=int, required=False, default=argparse.SUPPRESS)
      _parser.add_argument("----output-paths", dest="_output_paths", type=str, nargs=1)
      _parsed_args = vars(_parser.parse_args())
      _output_files = _parsed_args.pop("_output_paths", [])

      _outputs = train_model(**_parsed_args)

      _outputs = [_outputs]

      _output_serializers = [
          _serialize_str,

      ]

      import os
      for idx, output_file in enumerate(_output_files):
          try:
              os.makedirs(os.path.dirname(output_file))
          except OSError:
              pass
          with open(output_file, 'w') as f:
              f.write(_output_serializers[idx](_outputs[idx]))
    args:
    - --processed-path
    - {inputValue: processed_path}
    - --model-path
    - {inputValue: model_path}
    - if:
        cond: {isPresent: n_estimators}
        then:
        - --n-estimators
        - {inputValue: n_estimators}
    - '----output-paths'
    - {outputPath: Output}
